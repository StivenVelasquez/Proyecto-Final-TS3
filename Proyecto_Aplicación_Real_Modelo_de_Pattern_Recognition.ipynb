{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMfi6cpZ2SIG/YvQdLDZYX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StivenVelasquez/Proyecto-Final-TS3/blob/main/Proyecto_Aplicaci%C3%B3n_Real_Modelo_de_Pattern_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><strong><em>PROYECTO FINAL: APLICACIÓN REAL DEL MODELO DE PATTERN RECOGNITION</center>\n",
        "\n",
        "<div align=\"justify\">\n",
        "Integrantes:\n",
        "\n",
        "<div align=\"justify\"></em></strong></div>\n",
        "Stiven Velásquez López\n",
        "<div align=\"justify\">\n",
        "Yeiner Pájaro Otero"
      ],
      "metadata": {
        "id": "ROgc6cLQuMxr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kLImsK3huLsf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from ipywidgets import interact\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd  # for csv files and dataframe\n",
        "\n",
        "# Load the breast cancer dataset\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Extract the features (X) and the target variable (y)\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Print the shape of the dataset\n",
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of y:\", y.shape)\n",
        "\n",
        "# Print the feature names\n",
        "print(\"Feature names:\", data.feature_names)\n",
        "\n",
        "# Print the class labels\n",
        "print(\"Class labels:\", data.target_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCg9dMGPuZCb",
        "outputId": "9db2744f-4c53-418b-b54b-6797aac11752"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (569, 30)\n",
            "Shape of y: (569,)\n",
            "Feature names: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
            "Class labels: ['malignant' 'benign']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un DataFrame de Pandas con los datos y las características\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "\n",
        "# Agregar la columna de la variable objetivo al DataFrame\n",
        "df['target'] = data.target\n",
        "\n",
        "# Mostrar una vista previa de las primeras filas del DataFrame\n",
        "df.head(30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NVMLNBivucU4",
        "outputId": "1b15c0df-67c5-4efd-ffad-afede81c208c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0        17.990         10.38          122.80     1001.0          0.11840   \n",
              "1        20.570         17.77          132.90     1326.0          0.08474   \n",
              "2        19.690         21.25          130.00     1203.0          0.10960   \n",
              "3        11.420         20.38           77.58      386.1          0.14250   \n",
              "4        20.290         14.34          135.10     1297.0          0.10030   \n",
              "5        12.450         15.70           82.57      477.1          0.12780   \n",
              "6        18.250         19.98          119.60     1040.0          0.09463   \n",
              "7        13.710         20.83           90.20      577.9          0.11890   \n",
              "8        13.000         21.82           87.50      519.8          0.12730   \n",
              "9        12.460         24.04           83.97      475.9          0.11860   \n",
              "10       16.020         23.24          102.70      797.8          0.08206   \n",
              "11       15.780         17.89          103.60      781.0          0.09710   \n",
              "12       19.170         24.80          132.40     1123.0          0.09740   \n",
              "13       15.850         23.95          103.70      782.7          0.08401   \n",
              "14       13.730         22.61           93.60      578.3          0.11310   \n",
              "15       14.540         27.54           96.73      658.8          0.11390   \n",
              "16       14.680         20.13           94.74      684.5          0.09867   \n",
              "17       16.130         20.68          108.10      798.8          0.11700   \n",
              "18       19.810         22.15          130.00     1260.0          0.09831   \n",
              "19       13.540         14.36           87.46      566.3          0.09779   \n",
              "20       13.080         15.71           85.63      520.0          0.10750   \n",
              "21        9.504         12.44           60.34      273.9          0.10240   \n",
              "22       15.340         14.26          102.50      704.4          0.10730   \n",
              "23       21.160         23.04          137.20     1404.0          0.09428   \n",
              "24       16.650         21.38          110.00      904.6          0.11210   \n",
              "25       17.140         16.40          116.00      912.7          0.11860   \n",
              "26       14.580         21.53           97.41      644.8          0.10540   \n",
              "27       18.610         20.25          122.10     1094.0          0.09440   \n",
              "28       15.300         25.27          102.40      732.4          0.10820   \n",
              "29       17.570         15.05          115.00      955.1          0.09847   \n",
              "\n",
              "    mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0            0.27760         0.30010              0.14710         0.2419   \n",
              "1            0.07864         0.08690              0.07017         0.1812   \n",
              "2            0.15990         0.19740              0.12790         0.2069   \n",
              "3            0.28390         0.24140              0.10520         0.2597   \n",
              "4            0.13280         0.19800              0.10430         0.1809   \n",
              "5            0.17000         0.15780              0.08089         0.2087   \n",
              "6            0.10900         0.11270              0.07400         0.1794   \n",
              "7            0.16450         0.09366              0.05985         0.2196   \n",
              "8            0.19320         0.18590              0.09353         0.2350   \n",
              "9            0.23960         0.22730              0.08543         0.2030   \n",
              "10           0.06669         0.03299              0.03323         0.1528   \n",
              "11           0.12920         0.09954              0.06606         0.1842   \n",
              "12           0.24580         0.20650              0.11180         0.2397   \n",
              "13           0.10020         0.09938              0.05364         0.1847   \n",
              "14           0.22930         0.21280              0.08025         0.2069   \n",
              "15           0.15950         0.16390              0.07364         0.2303   \n",
              "16           0.07200         0.07395              0.05259         0.1586   \n",
              "17           0.20220         0.17220              0.10280         0.2164   \n",
              "18           0.10270         0.14790              0.09498         0.1582   \n",
              "19           0.08129         0.06664              0.04781         0.1885   \n",
              "20           0.12700         0.04568              0.03110         0.1967   \n",
              "21           0.06492         0.02956              0.02076         0.1815   \n",
              "22           0.21350         0.20770              0.09756         0.2521   \n",
              "23           0.10220         0.10970              0.08632         0.1769   \n",
              "24           0.14570         0.15250              0.09170         0.1995   \n",
              "25           0.22760         0.22290              0.14010         0.3040   \n",
              "26           0.18680         0.14250              0.08783         0.2252   \n",
              "27           0.10660         0.14900              0.07731         0.1697   \n",
              "28           0.16970         0.16830              0.08751         0.1926   \n",
              "29           0.11570         0.09875              0.07953         0.1739   \n",
              "\n",
              "    mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
              "0                  0.07871  ...          17.33           184.60      2019.0   \n",
              "1                  0.05667  ...          23.41           158.80      1956.0   \n",
              "2                  0.05999  ...          25.53           152.50      1709.0   \n",
              "3                  0.09744  ...          26.50            98.87       567.7   \n",
              "4                  0.05883  ...          16.67           152.20      1575.0   \n",
              "5                  0.07613  ...          23.75           103.40       741.6   \n",
              "6                  0.05742  ...          27.66           153.20      1606.0   \n",
              "7                  0.07451  ...          28.14           110.60       897.0   \n",
              "8                  0.07389  ...          30.73           106.20       739.3   \n",
              "9                  0.08243  ...          40.68            97.65       711.4   \n",
              "10                 0.05697  ...          33.88           123.80      1150.0   \n",
              "11                 0.06082  ...          27.28           136.50      1299.0   \n",
              "12                 0.07800  ...          29.94           151.70      1332.0   \n",
              "13                 0.05338  ...          27.66           112.00       876.5   \n",
              "14                 0.07682  ...          32.01           108.80       697.7   \n",
              "15                 0.07077  ...          37.13           124.10       943.2   \n",
              "16                 0.05922  ...          30.88           123.40      1138.0   \n",
              "17                 0.07356  ...          31.48           136.80      1315.0   \n",
              "18                 0.05395  ...          30.88           186.80      2398.0   \n",
              "19                 0.05766  ...          19.26            99.70       711.2   \n",
              "20                 0.06811  ...          20.49            96.09       630.5   \n",
              "21                 0.06905  ...          15.66            65.13       314.9   \n",
              "22                 0.07032  ...          19.08           125.10       980.9   \n",
              "23                 0.05278  ...          35.59           188.00      2615.0   \n",
              "24                 0.06330  ...          31.56           177.00      2215.0   \n",
              "25                 0.07413  ...          21.40           152.40      1461.0   \n",
              "26                 0.06924  ...          33.21           122.40       896.9   \n",
              "27                 0.05699  ...          27.26           139.90      1403.0   \n",
              "28                 0.06540  ...          36.71           149.30      1269.0   \n",
              "29                 0.06149  ...          19.52           134.90      1227.0   \n",
              "\n",
              "    worst smoothness  worst compactness  worst concavity  \\\n",
              "0             0.1622             0.6656          0.71190   \n",
              "1             0.1238             0.1866          0.24160   \n",
              "2             0.1444             0.4245          0.45040   \n",
              "3             0.2098             0.8663          0.68690   \n",
              "4             0.1374             0.2050          0.40000   \n",
              "5             0.1791             0.5249          0.53550   \n",
              "6             0.1442             0.2576          0.37840   \n",
              "7             0.1654             0.3682          0.26780   \n",
              "8             0.1703             0.5401          0.53900   \n",
              "9             0.1853             1.0580          1.10500   \n",
              "10            0.1181             0.1551          0.14590   \n",
              "11            0.1396             0.5609          0.39650   \n",
              "12            0.1037             0.3903          0.36390   \n",
              "13            0.1131             0.1924          0.23220   \n",
              "14            0.1651             0.7725          0.69430   \n",
              "15            0.1678             0.6577          0.70260   \n",
              "16            0.1464             0.1871          0.29140   \n",
              "17            0.1789             0.4233          0.47840   \n",
              "18            0.1512             0.3150          0.53720   \n",
              "19            0.1440             0.1773          0.23900   \n",
              "20            0.1312             0.2776          0.18900   \n",
              "21            0.1324             0.1148          0.08867   \n",
              "22            0.1390             0.5954          0.63050   \n",
              "23            0.1401             0.2600          0.31550   \n",
              "24            0.1805             0.3578          0.46950   \n",
              "25            0.1545             0.3949          0.38530   \n",
              "26            0.1525             0.6643          0.55390   \n",
              "27            0.1338             0.2117          0.34460   \n",
              "28            0.1641             0.6110          0.63350   \n",
              "29            0.1255             0.2812          0.24890   \n",
              "\n",
              "    worst concave points  worst symmetry  worst fractal dimension  target  \n",
              "0                0.26540          0.4601                  0.11890       0  \n",
              "1                0.18600          0.2750                  0.08902       0  \n",
              "2                0.24300          0.3613                  0.08758       0  \n",
              "3                0.25750          0.6638                  0.17300       0  \n",
              "4                0.16250          0.2364                  0.07678       0  \n",
              "5                0.17410          0.3985                  0.12440       0  \n",
              "6                0.19320          0.3063                  0.08368       0  \n",
              "7                0.15560          0.3196                  0.11510       0  \n",
              "8                0.20600          0.4378                  0.10720       0  \n",
              "9                0.22100          0.4366                  0.20750       0  \n",
              "10               0.09975          0.2948                  0.08452       0  \n",
              "11               0.18100          0.3792                  0.10480       0  \n",
              "12               0.17670          0.3176                  0.10230       0  \n",
              "13               0.11190          0.2809                  0.06287       0  \n",
              "14               0.22080          0.3596                  0.14310       0  \n",
              "15               0.17120          0.4218                  0.13410       0  \n",
              "16               0.16090          0.3029                  0.08216       0  \n",
              "17               0.20730          0.3706                  0.11420       0  \n",
              "18               0.23880          0.2768                  0.07615       0  \n",
              "19               0.12880          0.2977                  0.07259       1  \n",
              "20               0.07283          0.3184                  0.08183       1  \n",
              "21               0.06227          0.2450                  0.07773       1  \n",
              "22               0.23930          0.4667                  0.09946       0  \n",
              "23               0.20090          0.2822                  0.07526       0  \n",
              "24               0.20950          0.3613                  0.09564       0  \n",
              "25               0.25500          0.4066                  0.10590       0  \n",
              "26               0.27010          0.4264                  0.12750       0  \n",
              "27               0.14900          0.2341                  0.07421       0  \n",
              "28               0.20240          0.4027                  0.09876       0  \n",
              "29               0.14560          0.2756                  0.07919       0  \n",
              "\n",
              "[30 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba10a6ec-979a-411d-9203-dd7d04e70f9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.990</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.71190</td>\n",
              "      <td>0.26540</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.570</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.24160</td>\n",
              "      <td>0.18600</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.690</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.45040</td>\n",
              "      <td>0.24300</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.420</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.68690</td>\n",
              "      <td>0.25750</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.290</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.40000</td>\n",
              "      <td>0.16250</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>12.450</td>\n",
              "      <td>15.70</td>\n",
              "      <td>82.57</td>\n",
              "      <td>477.1</td>\n",
              "      <td>0.12780</td>\n",
              "      <td>0.17000</td>\n",
              "      <td>0.15780</td>\n",
              "      <td>0.08089</td>\n",
              "      <td>0.2087</td>\n",
              "      <td>0.07613</td>\n",
              "      <td>...</td>\n",
              "      <td>23.75</td>\n",
              "      <td>103.40</td>\n",
              "      <td>741.6</td>\n",
              "      <td>0.1791</td>\n",
              "      <td>0.5249</td>\n",
              "      <td>0.53550</td>\n",
              "      <td>0.17410</td>\n",
              "      <td>0.3985</td>\n",
              "      <td>0.12440</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>18.250</td>\n",
              "      <td>19.98</td>\n",
              "      <td>119.60</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>0.09463</td>\n",
              "      <td>0.10900</td>\n",
              "      <td>0.11270</td>\n",
              "      <td>0.07400</td>\n",
              "      <td>0.1794</td>\n",
              "      <td>0.05742</td>\n",
              "      <td>...</td>\n",
              "      <td>27.66</td>\n",
              "      <td>153.20</td>\n",
              "      <td>1606.0</td>\n",
              "      <td>0.1442</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.37840</td>\n",
              "      <td>0.19320</td>\n",
              "      <td>0.3063</td>\n",
              "      <td>0.08368</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>13.710</td>\n",
              "      <td>20.83</td>\n",
              "      <td>90.20</td>\n",
              "      <td>577.9</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0.16450</td>\n",
              "      <td>0.09366</td>\n",
              "      <td>0.05985</td>\n",
              "      <td>0.2196</td>\n",
              "      <td>0.07451</td>\n",
              "      <td>...</td>\n",
              "      <td>28.14</td>\n",
              "      <td>110.60</td>\n",
              "      <td>897.0</td>\n",
              "      <td>0.1654</td>\n",
              "      <td>0.3682</td>\n",
              "      <td>0.26780</td>\n",
              "      <td>0.15560</td>\n",
              "      <td>0.3196</td>\n",
              "      <td>0.11510</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>13.000</td>\n",
              "      <td>21.82</td>\n",
              "      <td>87.50</td>\n",
              "      <td>519.8</td>\n",
              "      <td>0.12730</td>\n",
              "      <td>0.19320</td>\n",
              "      <td>0.18590</td>\n",
              "      <td>0.09353</td>\n",
              "      <td>0.2350</td>\n",
              "      <td>0.07389</td>\n",
              "      <td>...</td>\n",
              "      <td>30.73</td>\n",
              "      <td>106.20</td>\n",
              "      <td>739.3</td>\n",
              "      <td>0.1703</td>\n",
              "      <td>0.5401</td>\n",
              "      <td>0.53900</td>\n",
              "      <td>0.20600</td>\n",
              "      <td>0.4378</td>\n",
              "      <td>0.10720</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>12.460</td>\n",
              "      <td>24.04</td>\n",
              "      <td>83.97</td>\n",
              "      <td>475.9</td>\n",
              "      <td>0.11860</td>\n",
              "      <td>0.23960</td>\n",
              "      <td>0.22730</td>\n",
              "      <td>0.08543</td>\n",
              "      <td>0.2030</td>\n",
              "      <td>0.08243</td>\n",
              "      <td>...</td>\n",
              "      <td>40.68</td>\n",
              "      <td>97.65</td>\n",
              "      <td>711.4</td>\n",
              "      <td>0.1853</td>\n",
              "      <td>1.0580</td>\n",
              "      <td>1.10500</td>\n",
              "      <td>0.22100</td>\n",
              "      <td>0.4366</td>\n",
              "      <td>0.20750</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>16.020</td>\n",
              "      <td>23.24</td>\n",
              "      <td>102.70</td>\n",
              "      <td>797.8</td>\n",
              "      <td>0.08206</td>\n",
              "      <td>0.06669</td>\n",
              "      <td>0.03299</td>\n",
              "      <td>0.03323</td>\n",
              "      <td>0.1528</td>\n",
              "      <td>0.05697</td>\n",
              "      <td>...</td>\n",
              "      <td>33.88</td>\n",
              "      <td>123.80</td>\n",
              "      <td>1150.0</td>\n",
              "      <td>0.1181</td>\n",
              "      <td>0.1551</td>\n",
              "      <td>0.14590</td>\n",
              "      <td>0.09975</td>\n",
              "      <td>0.2948</td>\n",
              "      <td>0.08452</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>15.780</td>\n",
              "      <td>17.89</td>\n",
              "      <td>103.60</td>\n",
              "      <td>781.0</td>\n",
              "      <td>0.09710</td>\n",
              "      <td>0.12920</td>\n",
              "      <td>0.09954</td>\n",
              "      <td>0.06606</td>\n",
              "      <td>0.1842</td>\n",
              "      <td>0.06082</td>\n",
              "      <td>...</td>\n",
              "      <td>27.28</td>\n",
              "      <td>136.50</td>\n",
              "      <td>1299.0</td>\n",
              "      <td>0.1396</td>\n",
              "      <td>0.5609</td>\n",
              "      <td>0.39650</td>\n",
              "      <td>0.18100</td>\n",
              "      <td>0.3792</td>\n",
              "      <td>0.10480</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>19.170</td>\n",
              "      <td>24.80</td>\n",
              "      <td>132.40</td>\n",
              "      <td>1123.0</td>\n",
              "      <td>0.09740</td>\n",
              "      <td>0.24580</td>\n",
              "      <td>0.20650</td>\n",
              "      <td>0.11180</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07800</td>\n",
              "      <td>...</td>\n",
              "      <td>29.94</td>\n",
              "      <td>151.70</td>\n",
              "      <td>1332.0</td>\n",
              "      <td>0.1037</td>\n",
              "      <td>0.3903</td>\n",
              "      <td>0.36390</td>\n",
              "      <td>0.17670</td>\n",
              "      <td>0.3176</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>15.850</td>\n",
              "      <td>23.95</td>\n",
              "      <td>103.70</td>\n",
              "      <td>782.7</td>\n",
              "      <td>0.08401</td>\n",
              "      <td>0.10020</td>\n",
              "      <td>0.09938</td>\n",
              "      <td>0.05364</td>\n",
              "      <td>0.1847</td>\n",
              "      <td>0.05338</td>\n",
              "      <td>...</td>\n",
              "      <td>27.66</td>\n",
              "      <td>112.00</td>\n",
              "      <td>876.5</td>\n",
              "      <td>0.1131</td>\n",
              "      <td>0.1924</td>\n",
              "      <td>0.23220</td>\n",
              "      <td>0.11190</td>\n",
              "      <td>0.2809</td>\n",
              "      <td>0.06287</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>13.730</td>\n",
              "      <td>22.61</td>\n",
              "      <td>93.60</td>\n",
              "      <td>578.3</td>\n",
              "      <td>0.11310</td>\n",
              "      <td>0.22930</td>\n",
              "      <td>0.21280</td>\n",
              "      <td>0.08025</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.07682</td>\n",
              "      <td>...</td>\n",
              "      <td>32.01</td>\n",
              "      <td>108.80</td>\n",
              "      <td>697.7</td>\n",
              "      <td>0.1651</td>\n",
              "      <td>0.7725</td>\n",
              "      <td>0.69430</td>\n",
              "      <td>0.22080</td>\n",
              "      <td>0.3596</td>\n",
              "      <td>0.14310</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>14.540</td>\n",
              "      <td>27.54</td>\n",
              "      <td>96.73</td>\n",
              "      <td>658.8</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.15950</td>\n",
              "      <td>0.16390</td>\n",
              "      <td>0.07364</td>\n",
              "      <td>0.2303</td>\n",
              "      <td>0.07077</td>\n",
              "      <td>...</td>\n",
              "      <td>37.13</td>\n",
              "      <td>124.10</td>\n",
              "      <td>943.2</td>\n",
              "      <td>0.1678</td>\n",
              "      <td>0.6577</td>\n",
              "      <td>0.70260</td>\n",
              "      <td>0.17120</td>\n",
              "      <td>0.4218</td>\n",
              "      <td>0.13410</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>14.680</td>\n",
              "      <td>20.13</td>\n",
              "      <td>94.74</td>\n",
              "      <td>684.5</td>\n",
              "      <td>0.09867</td>\n",
              "      <td>0.07200</td>\n",
              "      <td>0.07395</td>\n",
              "      <td>0.05259</td>\n",
              "      <td>0.1586</td>\n",
              "      <td>0.05922</td>\n",
              "      <td>...</td>\n",
              "      <td>30.88</td>\n",
              "      <td>123.40</td>\n",
              "      <td>1138.0</td>\n",
              "      <td>0.1464</td>\n",
              "      <td>0.1871</td>\n",
              "      <td>0.29140</td>\n",
              "      <td>0.16090</td>\n",
              "      <td>0.3029</td>\n",
              "      <td>0.08216</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>16.130</td>\n",
              "      <td>20.68</td>\n",
              "      <td>108.10</td>\n",
              "      <td>798.8</td>\n",
              "      <td>0.11700</td>\n",
              "      <td>0.20220</td>\n",
              "      <td>0.17220</td>\n",
              "      <td>0.10280</td>\n",
              "      <td>0.2164</td>\n",
              "      <td>0.07356</td>\n",
              "      <td>...</td>\n",
              "      <td>31.48</td>\n",
              "      <td>136.80</td>\n",
              "      <td>1315.0</td>\n",
              "      <td>0.1789</td>\n",
              "      <td>0.4233</td>\n",
              "      <td>0.47840</td>\n",
              "      <td>0.20730</td>\n",
              "      <td>0.3706</td>\n",
              "      <td>0.11420</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19.810</td>\n",
              "      <td>22.15</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1260.0</td>\n",
              "      <td>0.09831</td>\n",
              "      <td>0.10270</td>\n",
              "      <td>0.14790</td>\n",
              "      <td>0.09498</td>\n",
              "      <td>0.1582</td>\n",
              "      <td>0.05395</td>\n",
              "      <td>...</td>\n",
              "      <td>30.88</td>\n",
              "      <td>186.80</td>\n",
              "      <td>2398.0</td>\n",
              "      <td>0.1512</td>\n",
              "      <td>0.3150</td>\n",
              "      <td>0.53720</td>\n",
              "      <td>0.23880</td>\n",
              "      <td>0.2768</td>\n",
              "      <td>0.07615</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>13.540</td>\n",
              "      <td>14.36</td>\n",
              "      <td>87.46</td>\n",
              "      <td>566.3</td>\n",
              "      <td>0.09779</td>\n",
              "      <td>0.08129</td>\n",
              "      <td>0.06664</td>\n",
              "      <td>0.04781</td>\n",
              "      <td>0.1885</td>\n",
              "      <td>0.05766</td>\n",
              "      <td>...</td>\n",
              "      <td>19.26</td>\n",
              "      <td>99.70</td>\n",
              "      <td>711.2</td>\n",
              "      <td>0.1440</td>\n",
              "      <td>0.1773</td>\n",
              "      <td>0.23900</td>\n",
              "      <td>0.12880</td>\n",
              "      <td>0.2977</td>\n",
              "      <td>0.07259</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>13.080</td>\n",
              "      <td>15.71</td>\n",
              "      <td>85.63</td>\n",
              "      <td>520.0</td>\n",
              "      <td>0.10750</td>\n",
              "      <td>0.12700</td>\n",
              "      <td>0.04568</td>\n",
              "      <td>0.03110</td>\n",
              "      <td>0.1967</td>\n",
              "      <td>0.06811</td>\n",
              "      <td>...</td>\n",
              "      <td>20.49</td>\n",
              "      <td>96.09</td>\n",
              "      <td>630.5</td>\n",
              "      <td>0.1312</td>\n",
              "      <td>0.2776</td>\n",
              "      <td>0.18900</td>\n",
              "      <td>0.07283</td>\n",
              "      <td>0.3184</td>\n",
              "      <td>0.08183</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>9.504</td>\n",
              "      <td>12.44</td>\n",
              "      <td>60.34</td>\n",
              "      <td>273.9</td>\n",
              "      <td>0.10240</td>\n",
              "      <td>0.06492</td>\n",
              "      <td>0.02956</td>\n",
              "      <td>0.02076</td>\n",
              "      <td>0.1815</td>\n",
              "      <td>0.06905</td>\n",
              "      <td>...</td>\n",
              "      <td>15.66</td>\n",
              "      <td>65.13</td>\n",
              "      <td>314.9</td>\n",
              "      <td>0.1324</td>\n",
              "      <td>0.1148</td>\n",
              "      <td>0.08867</td>\n",
              "      <td>0.06227</td>\n",
              "      <td>0.2450</td>\n",
              "      <td>0.07773</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>15.340</td>\n",
              "      <td>14.26</td>\n",
              "      <td>102.50</td>\n",
              "      <td>704.4</td>\n",
              "      <td>0.10730</td>\n",
              "      <td>0.21350</td>\n",
              "      <td>0.20770</td>\n",
              "      <td>0.09756</td>\n",
              "      <td>0.2521</td>\n",
              "      <td>0.07032</td>\n",
              "      <td>...</td>\n",
              "      <td>19.08</td>\n",
              "      <td>125.10</td>\n",
              "      <td>980.9</td>\n",
              "      <td>0.1390</td>\n",
              "      <td>0.5954</td>\n",
              "      <td>0.63050</td>\n",
              "      <td>0.23930</td>\n",
              "      <td>0.4667</td>\n",
              "      <td>0.09946</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>21.160</td>\n",
              "      <td>23.04</td>\n",
              "      <td>137.20</td>\n",
              "      <td>1404.0</td>\n",
              "      <td>0.09428</td>\n",
              "      <td>0.10220</td>\n",
              "      <td>0.10970</td>\n",
              "      <td>0.08632</td>\n",
              "      <td>0.1769</td>\n",
              "      <td>0.05278</td>\n",
              "      <td>...</td>\n",
              "      <td>35.59</td>\n",
              "      <td>188.00</td>\n",
              "      <td>2615.0</td>\n",
              "      <td>0.1401</td>\n",
              "      <td>0.2600</td>\n",
              "      <td>0.31550</td>\n",
              "      <td>0.20090</td>\n",
              "      <td>0.2822</td>\n",
              "      <td>0.07526</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>16.650</td>\n",
              "      <td>21.38</td>\n",
              "      <td>110.00</td>\n",
              "      <td>904.6</td>\n",
              "      <td>0.11210</td>\n",
              "      <td>0.14570</td>\n",
              "      <td>0.15250</td>\n",
              "      <td>0.09170</td>\n",
              "      <td>0.1995</td>\n",
              "      <td>0.06330</td>\n",
              "      <td>...</td>\n",
              "      <td>31.56</td>\n",
              "      <td>177.00</td>\n",
              "      <td>2215.0</td>\n",
              "      <td>0.1805</td>\n",
              "      <td>0.3578</td>\n",
              "      <td>0.46950</td>\n",
              "      <td>0.20950</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.09564</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>17.140</td>\n",
              "      <td>16.40</td>\n",
              "      <td>116.00</td>\n",
              "      <td>912.7</td>\n",
              "      <td>0.11860</td>\n",
              "      <td>0.22760</td>\n",
              "      <td>0.22290</td>\n",
              "      <td>0.14010</td>\n",
              "      <td>0.3040</td>\n",
              "      <td>0.07413</td>\n",
              "      <td>...</td>\n",
              "      <td>21.40</td>\n",
              "      <td>152.40</td>\n",
              "      <td>1461.0</td>\n",
              "      <td>0.1545</td>\n",
              "      <td>0.3949</td>\n",
              "      <td>0.38530</td>\n",
              "      <td>0.25500</td>\n",
              "      <td>0.4066</td>\n",
              "      <td>0.10590</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>14.580</td>\n",
              "      <td>21.53</td>\n",
              "      <td>97.41</td>\n",
              "      <td>644.8</td>\n",
              "      <td>0.10540</td>\n",
              "      <td>0.18680</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.08783</td>\n",
              "      <td>0.2252</td>\n",
              "      <td>0.06924</td>\n",
              "      <td>...</td>\n",
              "      <td>33.21</td>\n",
              "      <td>122.40</td>\n",
              "      <td>896.9</td>\n",
              "      <td>0.1525</td>\n",
              "      <td>0.6643</td>\n",
              "      <td>0.55390</td>\n",
              "      <td>0.27010</td>\n",
              "      <td>0.4264</td>\n",
              "      <td>0.12750</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>18.610</td>\n",
              "      <td>20.25</td>\n",
              "      <td>122.10</td>\n",
              "      <td>1094.0</td>\n",
              "      <td>0.09440</td>\n",
              "      <td>0.10660</td>\n",
              "      <td>0.14900</td>\n",
              "      <td>0.07731</td>\n",
              "      <td>0.1697</td>\n",
              "      <td>0.05699</td>\n",
              "      <td>...</td>\n",
              "      <td>27.26</td>\n",
              "      <td>139.90</td>\n",
              "      <td>1403.0</td>\n",
              "      <td>0.1338</td>\n",
              "      <td>0.2117</td>\n",
              "      <td>0.34460</td>\n",
              "      <td>0.14900</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>0.07421</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>15.300</td>\n",
              "      <td>25.27</td>\n",
              "      <td>102.40</td>\n",
              "      <td>732.4</td>\n",
              "      <td>0.10820</td>\n",
              "      <td>0.16970</td>\n",
              "      <td>0.16830</td>\n",
              "      <td>0.08751</td>\n",
              "      <td>0.1926</td>\n",
              "      <td>0.06540</td>\n",
              "      <td>...</td>\n",
              "      <td>36.71</td>\n",
              "      <td>149.30</td>\n",
              "      <td>1269.0</td>\n",
              "      <td>0.1641</td>\n",
              "      <td>0.6110</td>\n",
              "      <td>0.63350</td>\n",
              "      <td>0.20240</td>\n",
              "      <td>0.4027</td>\n",
              "      <td>0.09876</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>17.570</td>\n",
              "      <td>15.05</td>\n",
              "      <td>115.00</td>\n",
              "      <td>955.1</td>\n",
              "      <td>0.09847</td>\n",
              "      <td>0.11570</td>\n",
              "      <td>0.09875</td>\n",
              "      <td>0.07953</td>\n",
              "      <td>0.1739</td>\n",
              "      <td>0.06149</td>\n",
              "      <td>...</td>\n",
              "      <td>19.52</td>\n",
              "      <td>134.90</td>\n",
              "      <td>1227.0</td>\n",
              "      <td>0.1255</td>\n",
              "      <td>0.2812</td>\n",
              "      <td>0.24890</td>\n",
              "      <td>0.14560</td>\n",
              "      <td>0.2756</td>\n",
              "      <td>0.07919</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba10a6ec-979a-411d-9203-dd7d04e70f9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ba10a6ec-979a-411d-9203-dd7d04e70f9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ba10a6ec-979a-411d-9203-dd7d04e70f9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecciona todas las filas y todas las columnas excepto la última (que contiene las etiquetas) del DataFrame 'df'\n",
        "# y se guarda como una matriz NumPy llamada 'X'\n",
        "X = df.iloc[:, :-1].values\n",
        "# Selecciona la columna 'target' del DataFrame 'df' y se guarda como una matriz NumPy llamada 'y'\n",
        "y = df['target'].values"
      ],
      "metadata": {
        "id": "xpFSKz4tux_S"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Normalizar los datos\n",
        "scaler = StandardScaler()\n",
        "X_norm = scaler.fit_transform(X)\n",
        "\n",
        "# Proyectar los datos en el espacio latente de diferentes dimensiones\n",
        "q_values = [2, 5, 10, 15, 20, 25, 30]\n",
        "acc_values_gnb = []\n",
        "acc_values_lr = []\n",
        "acc_values_svm = []\n",
        "acc_values_dt = []\n",
        "acc_values_rf = []\n",
        "\n",
        "for i, q in enumerate(q_values):\n",
        "    # Proyectar los datos en el espacio latente\n",
        "    pca = PCA(n_components=q)\n",
        "    Z = pca.fit_transform(X_norm)\n",
        "\n",
        "    # Dividir los datos en entrenamiento y prueba\n",
        "    X_train, X_test, y_train, y_test = train_test_split(Z, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Entrenar el modelo de regresión logística\n",
        "    lr = LogisticRegression()\n",
        "    lr.fit(X_train, y_train)\n",
        "\n",
        "    # Entrenar el modelo de clasificación Bayesiano\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(X_train, y_train)\n",
        "\n",
        "    # Entrenar el modelo de SVM\n",
        "    svm = SVC()\n",
        "    svm.fit(X_train, y_train)\n",
        "\n",
        "    # Entrenar el modelo de arbol de decisión\n",
        "    dt = DecisionTreeClassifier()\n",
        "    dt.fit(X_train, y_train)\n",
        "\n",
        "    # Entrenar el modelo de  RandomForest\n",
        "    rf = RandomForestClassifier()\n",
        "    rf.fit(X_train, y_train)\n",
        "\n",
        "    # Predecir las etiquetas en el conjunto de prueba\n",
        "    y_pred_gnb = gnb.predict(X_test)\n",
        "    y_pred_lr = lr.predict(X_test)\n",
        "    y_pred_svm = svm.predict(X_test)\n",
        "    y_pred_rf = rf.predict(X_test)\n",
        "    y_pred_dt = dt.predict(X_test)\n",
        "\n",
        "    # Evaluar el desempeño de los modelos\n",
        "    acc_gnb = accuracy_score(y_test, y_pred_gnb)\n",
        "    acc_lr = accuracy_score(y_test, y_pred_lr)\n",
        "    acc_svm = accuracy_score(y_test, y_pred_svm)\n",
        "    acc_dt = accuracy_score(y_test, y_pred_dt)\n",
        "    acc_rf = accuracy_score(y_test, y_pred_rf)\n",
        "\n",
        "    print('Accuracy del modelo de clasificación Bayesiano con %d componentes: %.3f' % (q, acc_gnb))\n",
        "    print('Accuracy del modelo de regresión logística con %d componentes: %.3f' % (q, acc_lr))\n",
        "    print('Accuracy del modelo de Support Vector Machine (SVM)  con %d componentes: %.3f' % (q, acc_svm))\n",
        "    print('Accuracy del modelo de Arbol de Decisión con %d componentes: %.3f' % (q, acc_dt))\n",
        "    print('Accuracy del modelo de Random Forest  con %d componentes: %.3f' % (q, acc_rf))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-1PEWWyu9kt",
        "outputId": "55f2d5f4-b13f-4758-eea8-2ec606e8e815"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy del modelo de clasificación Bayesiano con 2 componentes: 0.918\n",
            "Accuracy del modelo de regresión logística con 2 componentes: 0.971\n",
            "Accuracy del modelo de Support Vector Machine (SVM)  con 2 componentes: 0.936\n",
            "Accuracy del modelo de Arbol de Decisión con 2 componentes: 0.936\n",
            "Accuracy del modelo de Random Forest  con 2 componentes: 0.947\n",
            "\n",
            "Accuracy del modelo de clasificación Bayesiano con 5 componentes: 0.930\n",
            "Accuracy del modelo de regresión logística con 5 componentes: 0.988\n",
            "Accuracy del modelo de Support Vector Machine (SVM)  con 5 componentes: 0.971\n",
            "Accuracy del modelo de Arbol de Decisión con 5 componentes: 0.942\n",
            "Accuracy del modelo de Random Forest  con 5 componentes: 0.965\n",
            "\n",
            "Accuracy del modelo de clasificación Bayesiano con 10 componentes: 0.912\n",
            "Accuracy del modelo de regresión logística con 10 componentes: 0.982\n",
            "Accuracy del modelo de Support Vector Machine (SVM)  con 10 componentes: 0.965\n",
            "Accuracy del modelo de Arbol de Decisión con 10 componentes: 0.959\n",
            "Accuracy del modelo de Random Forest  con 10 componentes: 0.959\n",
            "\n",
            "Accuracy del modelo de clasificación Bayesiano con 15 componentes: 0.901\n",
            "Accuracy del modelo de regresión logística con 15 componentes: 0.988\n",
            "Accuracy del modelo de Support Vector Machine (SVM)  con 15 componentes: 0.977\n",
            "Accuracy del modelo de Arbol de Decisión con 15 componentes: 0.947\n",
            "Accuracy del modelo de Random Forest  con 15 componentes: 0.947\n",
            "\n",
            "Accuracy del modelo de clasificación Bayesiano con 20 componentes: 0.860\n",
            "Accuracy del modelo de regresión logística con 20 componentes: 0.988\n",
            "Accuracy del modelo de Support Vector Machine (SVM)  con 20 componentes: 0.971\n",
            "Accuracy del modelo de Arbol de Decisión con 20 componentes: 0.965\n",
            "Accuracy del modelo de Random Forest  con 20 componentes: 0.924\n",
            "\n",
            "Accuracy del modelo de clasificación Bayesiano con 25 componentes: 0.842\n",
            "Accuracy del modelo de regresión logística con 25 componentes: 0.982\n",
            "Accuracy del modelo de Support Vector Machine (SVM)  con 25 componentes: 0.971\n",
            "Accuracy del modelo de Arbol de Decisión con 25 componentes: 0.959\n",
            "Accuracy del modelo de Random Forest  con 25 componentes: 0.936\n",
            "\n",
            "Accuracy del modelo de clasificación Bayesiano con 30 componentes: 0.836\n",
            "Accuracy del modelo de regresión logística con 30 componentes: 0.982\n",
            "Accuracy del modelo de Support Vector Machine (SVM)  con 30 componentes: 0.971\n",
            "Accuracy del modelo de Arbol de Decisión con 30 componentes: 0.947\n",
            "Accuracy del modelo de Random Forest  con 30 componentes: 0.930\n",
            "\n"
          ]
        }
      ]
    }
  ]
}